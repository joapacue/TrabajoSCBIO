
##### Bibliotecas a importar ######

#Imports necesarios para la red
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications import Xception
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomZoom
from tensorflow.keras.applications.xception import preprocess_input, decode_predictions

#Imports necesarios para la captura de imágenes
import cv2
import os
import time


#### Carga inicial de variables
tam = 224
clase_manos = mp.solutions.hands
manos = clase_manos.Hands()
dibujo = mp.solutions.drawing_utils

#### Cargado del modelo
loaded_model = keras.models.load_model('./modelos/Modelo.h5')

#### Abriendo e inicializando cámara
cap = cv2.VideoCapture(0)

if not cap.isOpened():
	print("[ERROR] Error abriendo la cámara, es posible que otra aplicación la esté usando")	
	break
else:
	# Inicializamos un contador para regular los FPS de la captura
	timestamp = int(time.time())

while True:
	# Leemos un frame de la Webcam
        ret, frame = cap.read()
	color=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)#Pasamos de BGR a RGB
	copia=frame.copy()
	resultado = manos.process(color)
	posiciones = []

	if not ret:
        	print("[ERROR] Error leyendo frame, aboratando ejecución del programa")
        	break
        	
	if resultado.multi_hand_landmarks: #Si hay algo en los resultados entramos al if
		for mano in resultado.multi_hand_landmarks:  #Buscamos la mano dentro de la lista de manos que nos da el descriptor
			for id, lm in enumerate(mano.landmark):  #Vamos a obtener la informacion de cada mano encontrada por el ID
			#print(id,lm) #Como nos entregan decimales (Proporcion de la imagen) debemos pasarlo a pixeles
			alto, ancho, c = frame.shape  #Extraemos el ancho y el alto de los fotpgramas para multiplicarlos por la proporcion
			corx, cory = int(lm.x*ancho), int(lm.y*alto) #Extraemos la ubicacion de cada punto que pertence a la mano en coordenadas
			posiciones.append([id, corx, cory])
			dibujo.draw_landmarks(frame, mano, clase_manos.HAND_CONNECTIONS)
		if len(posiciones) != 0:
			pto_i5 = posiciones[9] #Punto central
			x1, y1 = (pto_i5[1]-round(tam/2)), (pto_i5[2]-round(tam/2)) #Obtenemos el punto incial y las longitudes
			x2, y2 = x1 + tam, y1 + tam
			dedos_reg = copia[y1:y2, x1:x2]
			cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)
		img = cv2.resize(dedos_reg, (tam, tam), interpolation=cv2.INTER_CUBIC) #Redimensionamos las fotos


	# Leemos el tiempo actual en millis y sólo llamamos a la red 2 veces por seg
	current_timestamp = time.time()
	if current_timestamp > timestamp+0.5:
		#img = image.load_img(img_path, target_size=(71, 71))
		#x = image.img_to_array(img)
		#x = np.expand_dims(x, axis=0)
		x = preprocess_input(img)

		preds = loaded_model.predict(x)

		for i in range(len(label_map)):
			print(label_map[i],preds[0][i])
			print('Salida:', label_map[np.argmax(preds)])


	if cv2.waitKey(1) & 0xFF == ord('q'):
		print("[INFO] Tecla Q presionada, abortando ejecución del programa")
		cap.release()
		cv2.destroyAllWindows()
		break





